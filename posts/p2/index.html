<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Some tasks I&rsquo;ve worked on &#183; Blog</title><link rel=prev href=/posts/p1/><link rel=next href=/posts/p3/><meta name=description content="Intro When I’m interviewing for contracts or for jobs, many times I get asked what are the hardest problems I’ve had to deal with. I’ll write below some of these problems as I remember them now.
   Double-counting Some years ago, I was working as a consultant in the analytics team of a top-10 Alexa website with hundreds of millions of views every month. I was tasked with finding a bug in the code that was counting page views."><meta name=keywords content="databases,logs,monitoring,analytics,postgresql,interviews"><meta property="og:title" content="Some tasks I've worked on"><meta property="og:description" content="Intro When I’m interviewing for contracts or for jobs, many times I get asked what are the hardest problems I’ve had to deal with. I’ll write below some of these problems as I remember them now.
   Double-counting Some years ago, I was working as a consultant in the analytics team of a top-10 Alexa website with hundreds of millions of views every month. I was tasked with finding a bug in the code that was counting page views."><meta property="article:published_time" content="2021-02-20T00:00:00+00:00"><meta property="article:modified_time" content="2021-02-20T00:00:00+00:00"><meta property="og:site_name" content="Blog"><meta property="article:section" content="posts"><meta property="article:tag" content="databases"><meta property="article:tag" content="logs"><meta property="article:tag" content="monitoring"><meta property="article:tag" content="analytics"><meta property="article:tag" content="postgresql"><meta property="article:tag" content="interviews"><meta name=twitter:card content="summary"><meta name=twitter:title content="Some tasks I've worked on"><meta name=twitter:description content="Intro When I’m interviewing for contracts or for jobs, many times I get asked what are the hardest problems I’ve had to deal with. I’ll write below some of these problems as I remember them now. …"><meta name=generator content="Hugo 0.79.1"><link rel=stylesheet href=/css/site.min.72989e8586a2239ea67ac4abbdb14c93dda32429d05c83e1eb621be0d97d1924.css integrity="sha256-cpiehYaiI56mesSrvbFMk92jJCnQXIPh62Ib4Nl9GSQ="></head><body class=article><header class=header><nav class=navbar><div class=navbar-brand><a class=navbar-item href=/>Blog</a>
<button class=navbar-burger data-target=topbar-nav>
<span></span><span></span><span></span></button></div><div id=topbar-nav class=navbar-menu><div class=navbar-end><a class=navbar-item href=/services/ title=Services>Services</a></div></div></nav></header><div class=body><div class=nav-container><aside class=nav><div class=panels><div class="nav-panel-menu is-active" data-panel=menu><nav class=nav-menu><h3 class=title><a href=/>Blog</a></h3><ul class=nav-list><li class=nav-item data-depth=0><button class=nav-item-toggle></button>
<a class=nav-link href=/posts/>Posts</a><ul class=nav-list><li class=nav-item data-depth=1><a class=nav-link href=/posts/p9/>Solving a simple puzzle using SymPy</a></li><li class=nav-item data-depth=1><a class=nav-link href=/posts/p8/>Building offline archives</a></li><li class=nav-item data-depth=1><a class=nav-link href=/posts/p7/>Packing, encrypting and uploading deliverables</a></li><li class=nav-item data-depth=1><a class=nav-link href=/posts/p6/>Multiple instance Activitywatch remote server setup for time tracking</a></li><li class=nav-item data-depth=1><a class=nav-link href=/posts/p5/>Creating mosaics, clipping and removing overlapping satellite images</a></li><li class=nav-item data-depth=1><a class=nav-link href=/posts/p4/>Polygon gridding using Geopandas and Shapely</a></li><li class=nav-item data-depth=1><a class=nav-link href=/posts/p3/>Fast sub-tree containment checks</a></li><li class="nav-item is-current-page" data-depth=1><a class=nav-link href=/posts/p2/>Some tasks I&rsquo;ve worked on</a></li><li class=nav-item data-depth=1><a class=nav-link href=/posts/p1/>Setting up the new blog</a></li></ul></li><li class=nav-item data-depth=0><a class=nav-link href=/services/>Services</a></li></ul></nav></div><div class=nav-panel-explore data-panel=explore style=display:none><div class=context><span class=title></span><span class=version></span></div></div></div></aside></div><main class=article><div class=toolbar role=navigation><button class=nav-toggle></button>
<a href=/ class=home-link></a><nav class=breadcrumbs aria-label=breadcrumbs><ul><li><a href=/>Blog</a></li><li><a href=/posts/>Posts</a></li><li>Some tasks I&rsquo;ve worked on</li></ul></nav></div><div class=content><article class=doc><h1 class=page>Some tasks I&rsquo;ve worked on</h1><div class="openblock is-before-toc"><div class=title>Posted on February 20, 2021
&#183; Tagged with
<a href=/tags/databases/>databases</a>, <a href=/tags/logs/>logs</a>, <a href=/tags/monitoring/>monitoring</a>, <a href=/tags/analytics/>analytics</a>, <a href=/tags/postgresql/>postgresql</a>, <a href=/tags/interviews/>interviews</a></div></div><div class=sect1><h2 id=_intro>Intro</h2><div class=sectionbody><div class=paragraph><p>When I’m interviewing for contracts or for jobs, many times I get asked
what are the hardest problems I’ve had to deal with. I’ll write below
some of these problems as I remember them now.</p></div></div></div><div class=sect1><h2 id=_double_counting>Double-counting</h2><div class=sectionbody><div class=paragraph><p>Some years ago, I was working as a consultant in the analytics team of a
top-10 Alexa website with hundreds of millions of views every month.
I was tasked with finding a bug in the code that was counting page views.</p></div><div class=paragraph><p>The code was counting the number of views coming from different
areas around the world. In order to summarize this vast amount
of data, and bucket it into geographical regions, it would have
to classify each city in the world to a certain region, and
there were two main regions that we were interested in:
<a href=https://en.wikipedia.org/wiki/Northern_Hemisphere>Northern Hemisphere</a>
vs. <a href=https://en.wikipedia.org/wiki/Southern_Hemisphere>Southern Hemisphere</a>.</p></div><div class=paragraph><p>The bug itself would manifest in the totals row, for the percentages of views.
Instead of having a grand total of <code>100%</code>, we had <code>100.41%</code>.</p></div><div class=paragraph><p>It was definitely a case of <a href=https://en.wikipedia.org/wiki/Double_counting_(fallacy)>double-counting</a> but
nobody knew exactly where it was coming from.</p></div><div class=paragraph><p>The codebase was a fairly large 40k lines of code Perl written in a very
arcane pre-Perl5 codingstyle. Tests were absent, and rewriting the code
to be object-oriented in order to be able to tests different parts of
the code in isolation was not an option given the size of the codebase.
Checking all the code, and the arithmetic operations would have taken way too much time
and effort.</p></div><div class=paragraph><p>Making changes to the code and re-running it on full or partial data
was also prohibitive because there were hundreds of gigabytes of data
to analyze in the full dataset.</p></div><div class=paragraph><p>After many days of looking at the code, and trying to understand where
the problem was coming from, I realized that the only chance I had was to try
to craft the simplest test possible.</p></div><div class=paragraph><p>Eventually I managed to craft that test: I wrote a program that would run the
Perl code with a one-line log file, each time with a different city on the planet.
Right after the Perl code was run, my program would check the reports generated
to see if the percentages were correct.</p></div><div class=paragraph><p>The data is split up by a CSV mapping(a <code>City→Hemisphere</code> mapping). The
planet was split into Northern/Southern hemispheres, which have cities
allocated to them and some cities were placed in both the northern and
southern CSV categories, resulting in counting the same numbers twice.</p></div><div class=paragraph><p>Running the code with one-line log lines, with just 1 city at a time,
revealed that for some cities (on some islands in the Atlantic Ocean)
the percentages were wrong(different than 100%), then grepping the codebase for
those cities also revealed the presence of the CSV files in question,
and that those cities were marked as being in both the Northern and the
Southern hemisphere CSV files. After an e-mail thread where the suggestion
of modifying the CSV file was discussed, the problem was solved.</p></div><div class=paragraph><p>In this case the bug was located in the data, and not the code itself.</p></div></div></div><div class=sect1><h2 id=_dashboard_dependencies>Dashboard dependencies</h2><div class=sectionbody><div class=paragraph><p>When I was working a devops position in an online gaming company, I was
handed a problem about dashboards being broken and reports in them not
showing up anymore.</p></div><div class=paragraph><p>The way these were structured was this: <code>Dashboards ⇒ Reports ⇒ Queries ⇒ Tables</code></p></div><div class=paragraph><p>So a dashboard had multiple reports, and reports were using queries,
and in turn queries were accessing data from tables (all these relations
we’ll call <em>references</em> or <em>links</em> later on).</p></div><div class=paragraph><p>The problem emerged after an upgrade of the visualization software
involved (this upgrade was done 10 months before I had joined the
company). Contacting the vendor support team resulted in an answer
like: <em>"Just upgrade to the next version"</em> (even when presented with a
full analysis of the problem). There were only two problems with that:</p></div><div class=ulist><ul><li><p>upgrading a running system with active users requires planning, approval, and sometimes
having a replica to do the upgrade on in order not to affect production and users if
something goes wrong during the upgrade</p></li><li><p>upgrading was exactly what broke the reports in the first place. so upgrading that
system again could have caused even more reports being broken</p></li></ul></div><div class=paragraph><p>I realized upgrading wouldn’t lead to a solution.</p></div><div class=paragraph><p>So I wrote code to dig into the metadata storage of the visualization software, reverse-engineered
the undocumented structure of the metadata, copied the data over to an
<a href=https://sqlite.org/index.html>SQLite</a> database (which I basically
used as a <a href=https://en.wikipedia.org/wiki/Graph_database>graph database</a> with nodes and edges) and came up with a
<a href=https://graphviz.org/>GraphViz</a>-based program that
was able to track object dependencies across upgrades. This
allowed me to then find the nodes that were pointed to by
<a href=https://en.wikipedia.org/wiki/Dangling_pointer>broken links</a> in the
dependency relations, and either re-create or update the objects in the
current version of the reports in order for them to work properly (the changes
performed were such that all references would point to valid objects).</p></div><div class=paragraph><p>At this point, visibility was increased, the entire hierarchy of
dependencies was clear.</p></div><div class=paragraph><p>Having done all of this made it easy to solve the next
task, which was to identify unused tables, by computing the
<a href=https://en.wikipedia.org/wiki/Degree_(graph_theory)>in-degree</a>
of each such table.</p></div></div></div><div class=sect1><h2 id=_identifying_wal_size_generated_by_queries>Identifying WAL size generated by queries</h2><div class=sectionbody><div class=paragraph><p>When I was working as a DBA at a telecom company we had some spikes in
the traffic of WAL logs in a PostgreSQL database that was replicated.
This was caused by some queries which would generate a lot of WAL, and
as a result there was more of it being transferred, it took longer for the
replica to apply all the WAL and catch up with the master, and that was
also causing a replication lag.</p></div><div class=paragraph><p>It turned out that I could actually use
<a href=https://www.postgresql.org/docs/11/pgwaldump.html><code>pg_waldump</code></a> to get
the transaction ids in each WAL file. In addition, I realized that if I
monitored the queries that were running on the database servers using the
<a href=https://www.postgresql.org/docs/11/monitoring-stats.html><code>pg_stat_activity</code></a>
catalog I could get the queries and their transaction ids. By joining
these two pieces of information, I was able to find out how much WAL
each query had generated, and then pick the outliers and report them
back to the teams that had written them, in order to be refactored.</p></div></div></div><div class=sect1><h2 id=_conclusion>Conclusion</h2><div class=sectionbody><div class=paragraph><p>Sometimes seemingly hard bugs can be solved by crafting the right kind
of test (which in turn shortens the cycle of trying out potential
fixes). Sometimes they require crafting new tools that increase
observability and visibility into the ways systems work.</p></div><div class="admonitionblock note"><table><tbody><tr><td class=icon><i class="fa icon-note" title=Note></i></td><td class=content>If you liked this article and would like to discuss more about these topics,
feel free to drop an e-mail at <a href=mailto:stefan.petrea@gmail.com>stefan.petrea@gmail.com</a>.</td></tr></tbody></table></div></div></div><nav class=pagination><span class=prev><a href=/posts/p1/>Setting up the new blog</a></span>
<span class=next><a href=/posts/p3/>Fast sub-tree containment checks</a></span></nav></article><aside class="toc sidebar" data-title data-levels=2><div class=toc-menu></div></aside></div></main></div><footer class=footer><p>This page was built with <a href=https://gohugo.io/>Hugo 0.79.1</a> using the <a href=https://github.com/basil/antora-default-ui-hugo-theme>Hugo port</a> of the <a href=https://gitlab.com/antora/antora-ui-default>Antora default UI</a>. The source code for this UI is licensed under the terms of the <a href=https://www.mozilla.org/en-US/MPL/2.0/>Mozilla Public License, Version 2.0</a> (MPL-2.0).</p></footer><div id=copy-to-clipboard style=display:none data-svg=/img/octicons-16.svg></div><script src=/js/site.min.da461a26436bc4ba84975879f2d7f90a593245b694bbea075400ef251e78b2e0.js integrity="sha256-2kYaJkNrxLqEl1h58tf5ClkyRbaUu+oHVADvJR54suA="></script><script src=/js/vendor/highlight.pack.79c21a0aa45cc5756c18c07f0cf37be9ad1e1b728f6f0e6b210c3913cfef592f.js integrity="sha256-ecIaCqRcxXVsGMB/DPN76a0eG3KPbw5rIQw5E8/vWS8="></script><script>;[].slice.call(document.querySelectorAll('pre code.hljs')).forEach(function(node){hljs.highlightBlock(node)})</script></body></html>